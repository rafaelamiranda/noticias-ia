<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Notícias de Inteligência Artificial (EN)</title>
    <link>https://github.com/rafaelamiranda/noticias-ia</link>
    <description>
Principais notícias relacionadas a inteligência artificial
dos últimos 7 dias, em Inglês.
    </description>
    <lastBuildDate>Sat, 16 Aug 2025 09:04:44 GMT</lastBuildDate>
    <item>
      <title>Decoding Palantir, the Most Mysterious Company in Silicon Valley</title>
      <link>https://www.wired.com/story/uncanny-valley-podcast-palantir-most-mysterious-company-silicon-valley/</link>
      <description>Save StorySave this story</description>
      <pubDate>Fri, 15 Aug 2025 18:46:13 GMT</pubDate>
      <guid>https://www.wired.com/story/uncanny-valley-podcast-palantir-most-mysterious-company-silicon-valley/</guid>
    </item>
    <item>
      <title>Developers Say GPT-5 Is a Mixed Bag</title>
      <link>https://www.wired.com/story/gpt-5-coding-review-software-engineering/</link>
      <description>Save StorySave this story</description>
      <pubDate>Fri, 15 Aug 2025 17:47:49 GMT</pubDate>
      <guid>https://www.wired.com/story/gpt-5-coding-review-software-engineering/</guid>
    </item>
    <item>
      <title>Sam Altman Says ChatGPT Is on Track to Out-Talk Humanity</title>
      <link>https://www.wired.com/story/sam-altman-says-chatgpt-is-on-track-to-out-talk-humanity/</link>
      <description>Save StorySave this story</description>
      <pubDate>Fri, 15 Aug 2025 16:17:30 GMT</pubDate>
      <guid>https://www.wired.com/story/sam-altman-says-chatgpt-is-on-track-to-out-talk-humanity/</guid>
    </item>
    <item>
      <title>‘Cheapfake’ AI Celeb Videos Are Rage-Baiting People on YouTube</title>
      <link>https://www.wired.com/story/cheapfake-ai-celeb-videos-are-rage-baiting-people-on-youtube/</link>
      <description>WIRED found over 100 YouTube channels using AI to create lazy fan-fiction-style videos. Despite being obviously fake, there’s a psychological reason people are falling for them.</description>
      <pubDate>Fri, 15 Aug 2025 11:00:00 GMT</pubDate>
      <guid>https://www.wired.com/story/cheapfake-ai-celeb-videos-are-rage-baiting-people-on-youtube/</guid>
    </item>
    <item>
      <title>NVIDIA aims to solve AI’s issues with many languages</title>
      <link>https://www.artificialintelligence-news.com/news/nvidia-aims-solve-ai-issues-with-many-languages/</link>
      <description>While AI might feel ubiquitous, it primarily operates in a tiny fraction of the world’s 7,000 languages, leaving a huge portion of the global population behind. NVIDIA aims to fix this glaring blind spot, particularly within Europe.The company has just released a powerful new set of open-source tools aimed at giving developers the power to build high-quality speech AI for 25 different European languages. This includes major languages, but more importantly, it offers a lifeline to those often overlooked by big tech, such as Croatian, Estonian, and Maltese.The goal is to let developers create the kind of voice-powered tools many of us take for granted, from multilingual chatbots that actually understand you to customer service bots and translation services that work in the blink of an eye.The centrepiece of this initiative is Granary, an enormous library of human speech. It contains around a million hours of audio, all curated to help teach AI the nuances of speech recognition and translation.To make use of this speech data, NVIDIA is also providing two new AI models designed for language tasks:Canary-1b-v2, a large model built for high accuracy on complex transcription and translation jobs.Parakeet-tdt-0.6b-v3, which is designed for real-time applications where speed is everything.If you’re keen to dive into the science behind it, the paper on Granary will be presented at the Interspeech conference in the Netherlands this month. For the developers eager to get their hands dirty, the dataset and both models are already available on Hugging Face.The real magic, however, lies in how this data was created. We all know that training AI requires vast amounts of data, but getting it is usually a slow, expensive, and frankly tedious process of human annotation.To get around this, NVIDIA’s speech AI team – working with researchers from Carnegie Mellon University and Fondazione Bruno Kessler – built an automated pipeline. Using their own NeMo toolkit, they were able to take raw, unlabelled audio and whip it into high-quality, structured data that an AI can learn from.This isn’t just a technical achievement; it’s a huge leap for digital inclusivity. It means a developer in Riga or Zagreb can finally build voice-powered AI tools that properly understand their local lang...</description>
      <pubDate>Fri, 15 Aug 2025 10:11:14 GMT</pubDate>
      <guid>https://www.artificialintelligence-news.com/news/nvidia-aims-solve-ai-issues-with-many-languages/</guid>
    </item>
    <item>
      <title>DeepSeek: The Chinese startup challenging Silicon Valley</title>
      <link>https://www.artificialintelligence-news.com/news/deepseek-the-chinese-startup-challenging-silicon-valley/</link>
      <description>Market disruption and shockwaves through Silicon Valley marked Chinese startup DeepSeek’s launch, challenging some of the fundamental assumptions of how artificial intelligence companies had operated and scaled.In less than a couple of years, the Beijing-based newcomer has accomplished what many thought impossible: creating AI models that compete with industry giants while spending only a fraction of their competitors’ budgets teaching models and inferring responses.The impact at the time of the public launch was immediate and measurable. According to the South China Morning Post, major tech stocks, including Nvidia, Microsoft, and Meta, experienced significant declines as investors grappled with the implications of DeepSeek’s existence.The startup’s free AI assistant application for iOS and Android, launched on January 10, quickly climbed to the top spot on Apple’s US App Store, displacing OpenAI’s ChatGPT and marking a historic first for a Chinese AI product in the American market.What makes this particularly significant is DeepSeek’s technological approach. The Algorithmic Bridge reports the company has implemented several innovative solutions, including Multi-head Latent Attention (MLA) to reduce memory bottlenecks and Group Relative Policy Optimisation (GRPO) to streamline reinforcement learning.The advances allow DeepSeek to achieve comparable or superior results to US competitors while using significantly fewer resources. The company’s resource efficiency is striking: DeepSeek operates with less than 100,000 H100 GPUs, while Meta will deploy 1.3 million GPUs by late 2025.The efficiency extends beyond hardware. The Algorithmic Bridge suggests that DeepSeek’s approach represents a tenfold improvement in resource utilisation when considering factors like development time and infrastructure costs.However, the rapid rise into Western users’ consciousness wasn’t without challenges. The South China Morning Post reported that DeepSeek’s sudden popularity led to significant infrastructure stress, resulting in server crashes and cybersecurity concerns that forced temporary registration limits. The growing pains highlight the real-world challenges of scaling AI services, regardless of architectural efficiency.The company’s commitment to open-source development ...</description>
      <pubDate>Fri, 15 Aug 2025 09:33:55 GMT</pubDate>
      <guid>https://www.artificialintelligence-news.com/news/deepseek-the-chinese-startup-challenging-silicon-valley/</guid>
    </item>
    <item>
      <title>Human-in-the-loop work drives AI powering Alibaba’s smart glasses</title>
      <link>https://www.artificialintelligence-news.com/news/human-in-the-loop-work-drives-ai-powering-alibabas-smart-glasses/</link>
      <description>Alibaba is moving into the smart glasses market with a device powered by its own AI models, part of a wider $52.4 billion furthering of AI and cloud computing. The Quark AI Glasses marks the company’s first step into the wearables category and is due to launch in China by the end of 2025.The glasses will run on Alibaba’s Qwen large language model and its AI assistant, Quark. Quark is already available as an app in China, but this will be the first time the company is pairing it with hardware to reach more users.The Hangzhou-based firm has been one of China’s more active AI developers, rolling out models designed to compete with systems from companies like OpenAI. By moving into smart glasses, it joins a growing group of tech players betting on wearables as the next major computing platform alongside smartphones.Pushing into hardwareThe Quark AI Glasses will enter a market that already includes Meta’s smart glasses made with Ray-Ban and a model launched this year by Xiaomi. Alibaba’s version will offer hands-free calling, music streaming, real-time translation, meeting transcription, and a built-in camera.Alibaba operates a broad set of services in China and the glasses will connect to that ecosystem. Users will be able to access navigation, make payments through Alipay, compare prices on Taobao, and tap into other Alibaba-owned platforms like mapping and travel booking.While the company has outlined some features, it has not revealed the price or detailed specifications.The data behind the devicesSmart glasses like Alibaba’s depend on AI systems that can recognise images, interpret context, and respond in natural language. The abilities rely on huge amounts of labelled data – information that has been reviewed and tagged by humans so the AI can learn from it.That process often involves “human-in-the-loop” (HITL) systems, where people provide input at key stages of training and testing. To understand how this works in practice, AI News spoke with Henry Chen, co-founder of Sapien, a company that manages large, distributed workforces for data labelling. Chen discussed common misunderstandings, the demand for skilled contributors, and how China’s AI growth is influencing the industry.Misconceptions about HITLOne common belief is that HITL is simply data labelli...</description>
      <pubDate>Fri, 15 Aug 2025 08:38:04 GMT</pubDate>
      <guid>https://www.artificialintelligence-news.com/news/human-in-the-loop-work-drives-ai-powering-alibabas-smart-glasses/</guid>
    </item>
    <item>
      <title>AI Slop Is Ripping Off One of Summer’s Best Games. Copycats Are Proving Hard to Kill</title>
      <link>https://www.wired.com/story/ai-slop-is-ripping-off-one-of-summers-best-games-fighting-back-is-harder-than-you-think/</link>
      <description>Peak has sold millions of copies and is Aggro Crab’s biggest hit to date. That makes it a prime target for cloning.</description>
      <pubDate>Thu, 14 Aug 2025 21:23:50 GMT</pubDate>
      <guid>https://www.wired.com/story/ai-slop-is-ripping-off-one-of-summers-best-games-fighting-back-is-harder-than-you-think/</guid>
    </item>
    <item>
      <title>Why Trump Flip-Flopped on Nvidia Selling H20 Chips to China</title>
      <link>https://www.wired.com/story/nvidia-chips-export-controls-trump-h20-security/</link>
      <description>Nvidia struck a surprising deal after convincing the president that H20 chips aren’t a national security risk. But whether the reversal is good or bad depends on who you ask.</description>
      <pubDate>Thu, 14 Aug 2025 19:56:42 GMT</pubDate>
      <guid>https://www.wired.com/story/nvidia-chips-export-controls-trump-h20-security/</guid>
    </item>
    <item>
      <title>Inside the Biden Administration&#x27;s Gamble to Freeze China’s AI Future</title>
      <link>https://www.wired.com/story/chips-china-artificial-intelligence-controls/</link>
      <description>Save StorySave this story</description>
      <pubDate>Thu, 14 Aug 2025 19:13:18 GMT</pubDate>
      <guid>https://www.wired.com/story/chips-china-artificial-intelligence-controls/</guid>
    </item>
    <item>
      <title>A DOGE AI Tool Called SweetREX Is Coming to Slash US Government Regulation</title>
      <link>https://www.wired.com/story/sweetrex-deregulation-ai-us-government-regulation-doge/</link>
      <description>Save StorySave this story</description>
      <pubDate>Thu, 14 Aug 2025 19:00:15 GMT</pubDate>
      <guid>https://www.wired.com/story/sweetrex-deregulation-ai-us-government-regulation-doge/</guid>
    </item>
    <item>
      <title>Watch Our Livestream Replay: What GPT-5 Means for ChatGPT Users</title>
      <link>https://www.wired.com/story/what-gpt-5-means-for-chatgpt-users/</link>
      <description>We answered your questions about OpenAI’s latest model, GPT-5, and what it means for the future of chatbots.</description>
      <pubDate>Thu, 14 Aug 2025 18:56:14 GMT</pubDate>
      <guid>https://www.wired.com/story/what-gpt-5-means-for-chatgpt-users/</guid>
    </item>
    <item>
      <title>xAI Was About to Land a Major Government Contract. Then Grok Praised Hitler</title>
      <link>https://www.wired.com/story/xai-grok-government-contract-hitler/</link>
      <description>Save StorySave this story</description>
      <pubDate>Thu, 14 Aug 2025 17:34:53 GMT</pubDate>
      <guid>https://www.wired.com/story/xai-grok-government-contract-hitler/</guid>
    </item>
    <item>
      <title>DeepSeek reverts to Nvidia for R2 model after Huawei AI chip fails</title>
      <link>https://www.artificialintelligence-news.com/news/deepseek-reverts-nvidia-r2-model-huawei-ai-chip-fails/</link>
      <description>DeepSeek’s plan to train its new AI model, R2, on Huawei’s Ascend chips has failed and forced a retreat to Nvidia while delaying launch.For months, the narrative pushed by Beijing has been one of unstoppable technological progress and a march towards self-sufficiency. However, reality has a habit of biting back. The recent troubles of Chinese AI darling DeepSeek is a textbook example of where ambition meets the hard wall of technical limitations.After the successful launch of its R1 model in January, DeepSeek found itself under pressure from China to champion the national cause. According to three people speaking to the Financial Times, the message was clear: use Huawei’s chips, not Nvidia’s.When it came to actually training their new R2 model, the sources say DeepSeek ran into “persistent technical issues” with Huawei’s AI chips. The problems were so fundamental that the project ground to a halt. A person with knowledge of the situation said this was the main reason the model’s planned launch in May was scrapped, putting the company on the back foot in a market that waits for no-one.To understand why this is such a big deal, you have to know the difference between AI training and inference. Training is the hard part, like sending a student to university for years of intense learning. It requires colossal amounts of power and stability. Inference is the relatively ‘easy’ part, like asking the graduate a question.DeepSeek discovered that while Huawei’s chips might be ready for the final exam, they weren’t yet up to the gruelling university course. The company had no choice but to switch back to Nvidia’s powerful systems to do the training. The sources say DeepSeek’s team is still trying to get the R2 model to work with Huawei chips for the less demanding inference stage.Two people confirmed that Huawei even sent its own team of engineers to DeepSeek’s offices to help them get the R2 model up and running on their chips. But even with the experts in the room, they couldn’t get a successful training run.Talk to anyone in the industry, and they’ll tell you this isn’t a huge surprise. Huawei CEO Ren Zhengfei even said earlier this year that the US “has exaggerated Huawei’s achievements” and the company “is not that great yet,” noting its best chips are still a ge...</description>
      <pubDate>Thu, 14 Aug 2025 16:04:50 GMT</pubDate>
      <guid>https://www.artificialintelligence-news.com/news/deepseek-reverts-nvidia-r2-model-huawei-ai-chip-fails/</guid>
    </item>
    <item>
      <title>Anthropic details its AI safety strategy</title>
      <link>https://www.artificialintelligence-news.com/news/anthropic-details-ai-safety-strategy/</link>
      <description>Anthropic has detailed its safety strategy to try and keep its popular AI model, Claude, helpful while avoiding perpetuating harms.Central to this effort is Anthropic’s Safeguards team; who aren’t your average tech support group, they’re a mix of policy experts, data scientists, engineers, and threat analysts who know how bad actors think.However, Anthropic’s approach to safety isn’t a single wall but more like a castle with multiple layers of defence. It all starts with creating the right rules and ends with hunting down new threats in the wild.First up is the Usage Policy, which is basically the rulebook for how Claude should and shouldn’t be used. It gives clear guidance on big issues like election integrity and child safety, and also on using Claude responsibly in sensitive fields like finance or healthcare.To shape these rules, the team uses a Unified Harm Framework. This helps them think through any potential negative impacts, from physical and psychological to economic and societal harm. It’s less of a formal grading system and more of a structured way to weigh the risks when making decisions. They also bring in outside experts for Policy Vulnerability Tests. These specialists in areas like terrorism and child safety try to “break” Claude with tough questions to see where the weaknesses are.We saw this in action during the 2024 US elections. After working with the Institute for Strategic Dialogue, Anthropic realised Claude might give out old voting information. So, they added a banner that pointed users to TurboVote, a reliable source for up-to-date, non-partisan election info.Teaching Claude right from wrongThe Anthropic Safeguards team works closely with the developers who train Claude to build safety from the start. This means deciding what kinds of things Claude should and shouldn’t do, and embedding those values into the model itself.They also team up with specialists to get this right. For example, by partnering with ThroughLine, a crisis support leader, they’ve taught Claude how to handle sensitive conversations about mental health and self-harm with care, rather than just refusing to talk. This careful training is why Claude will turn down requests to help with illegal activities, write malicious code, or create scams.Before any new version o...</description>
      <pubDate>Wed, 13 Aug 2025 09:55:27 GMT</pubDate>
      <guid>https://www.artificialintelligence-news.com/news/anthropic-details-ai-safety-strategy/</guid>
    </item>
    <item>
      <title>Can Huawei’s open-sourced CANN toolkit break the CUDA monopoly?</title>
      <link>https://www.artificialintelligence-news.com/news/huawei-nvidia-cann-cuda-open-source-challenge/</link>
      <description>A week after Huawei announced its decision to open-source the CANN (Compute Architecture for Neural Networks) software toolkit, the tech industry is still processing what this move means for the future of AI development.By making its Huawei CANN open source alternative to CUDA freely available to developers worldwide, the Chinese tech giant has fired what many consider a significant shot in the battle against NVIDIA’s two-decade and continuing dominance over AI computing.While it’s a notable challenge to the status quo, the real question is whether Huawei can overcome the substantial technical and systemic barriers that have kept CUDA virtually unchallenged for nearly twenty years.What is CANN and why does it matter?CANN is Huawei’s heterogeneous computing architecture that offers multi-level programming interfaces to help developers build AI applications optimised for Huawei’s Ascend AI GPUs. First introduced in 2018 as part of Huawei’s AI strategy, CANN serves as the company’s equivalent to NVIDIA’s CUDA platform.CANN provides APIs for AI applications on Ascend, giving developers several options for building high-level and performance-intensive applications. The architecture represents years of development aimed at creating a comprehensive software ecosystem around Huawei’s AI hardware.The strategic timing behind the open-source decisionHuawei’s decision to make CANN open-source comes at a particularly tense moment in US-China technology relations. Huawei’s rotating chairman Eric Xu Zhijun said the move would help “speed up innovation from developers” and “make Ascend easier to use” during the company’s developer conference in Beijing.The announcement follows closely after the Cyberspace Administration of China (CAC) launched an inquiry into NVIDIA, based on what it called “serious security issues” involving Nvidia’s processors and demands from US lawmakers to add tracking features to chips’ hardware.The regulatory scrutiny adds another layer of complexity to an already strained relationship between the two superpowers.CUDA’s monopolistic grip on AI developmentTo understand the significance of Huawei’s move, it’s important to examine NVIDIA’s CUDA dominance. CUDA, often described as a closed-off “moat” or, on occasion, “swamp,” has been viewed by some as ...</description>
      <pubDate>Wed, 13 Aug 2025 08:46:36 GMT</pubDate>
      <guid>https://www.artificialintelligence-news.com/news/huawei-nvidia-cann-cuda-open-source-challenge/</guid>
    </item>
    <item>
      <title>SoundHound is giving its AI the power of sight</title>
      <link>https://www.artificialintelligence-news.com/news/soundhound-is-giving-its-ai-the-power-of-sight/</link>
      <description>SoundHound AI, already a major player in voice assistants, is now giving its technology a pair of eyes.Imagine driving past a landmark and, without pulling out your phone, asking your car, “What’s that building over there?” and getting an instant answer. That’s what SoundHound AI is building. With the launch of Vision AI, SoundHound’s new system combines sight with sound to create a much smarter and more natural way to interact with technology. The idea is to mimic how we as humans operate; we don’t just listen to someone, we also see their gestures and what they’re looking at.By bringing this same contextual understanding to AI, SoundHound hopes to smooth over the clunky and often frustrating experience we have with many of today’s smart devices. The company is targeting real-world applications where this combined sense could make a huge difference, whether that’s in your next car, at the restaurant drive-thru, or a factory floor.Keyvan Mohajer, CEO of SoundHound AI, said: “At SoundHound, we believe the future of AI isn’t just multimodal—it’s deeply integrated, responsive, and built for real-world impact.“With Vision AI, we’re extending our leadership in voice and conversational AI to redefine how humans interact with products and services offered and used by businesses.”So, how does it work? Vision AI takes a live feed from a camera and fuses it with the company’s voice technology, which already excels at understanding natural speech. By processing what it sees and what it hears at the exact same time, the system can grasp the user’s true intent in a way a simple voice assistant never could.Think of a mechanic wearing smart glasses who can simply look at an engine part and ask for instructions, receiving instant visual and audio guidance without ever putting down their tools. In a shop, a staff member could scan shelves just by looking at them to get a real-time inventory count. For the rest of us, it might mean a drive-thru kiosk that visually confirms our order on screen the moment we say it.One of the biggest technical problems in creating such a system is ensuring the audio and visual elements are perfectly synchronised. Any lag would shatter the illusion of a natural conversation.Pranav Singh, VP of Engineering at SoundHound AI, commented: “With Visi...</description>
      <pubDate>Tue, 12 Aug 2025 10:06:54 GMT</pubDate>
      <guid>https://www.artificialintelligence-news.com/news/soundhound-is-giving-its-ai-the-power-of-sight/</guid>
    </item>
    <item>
      <title>NVIDIA latest: Blackwell GPU and software updates</title>
      <link>https://www.artificialintelligence-news.com/news/nvidia-expands-blackwell-powered-servers-with-new-ai-and-robotics-capabilities/</link>
      <description>NVIDIA’s latest RTX PRO 6000 Blackwell Server Edition GPU will soon be available in enterprise servers. Systems from Cisco, Dell Technologies, HPE, Lenovo, and Supermicro will ship various configurations in 2U servers. Nvidia says they will offer higher performance and efficiency for AI, graphics, simulation, analytics, and industrial applications, and support tasks like AI model […]
The post NVIDIA latest: Blackwell GPU and software updates appeared first on AI News.</description>
      <pubDate>Tue, 12 Aug 2025 09:16:33 GMT</pubDate>
      <guid>https://www.artificialintelligence-news.com/news/nvidia-expands-blackwell-powered-servers-with-new-ai-and-robotics-capabilities/</guid>
    </item>
  </channel>
</rss>